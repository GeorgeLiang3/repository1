{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T22:08:41.914041Z",
     "start_time": "2019-11-11T22:08:41.901243Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import edward2 as ed\n",
    "tfd = tfp.distributions\n",
    "import scipy.stats as st\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### negative log of the posterior\n",
    "\\begin{equation}\n",
    "\\left(\\frac{1}{2}\\left\\|\\mathbf{f}(\\mathrm{m})-\\mathbf{d}_{\\mathrm{obs}}\\right\\|_{\\mathrm{\\Gamma}_{\\mathrm{noise}}^{-1}}^{2}+\\frac{1}{2}\\left\\|\\mathrm{m}-\\mathrm{m}_{\\mathrm{prior}}\\right\\|_{C_{\\mathrm{prior}}^{-1}}^{2}\\right)\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T14:09:03.619733Z",
     "start_time": "2019-11-12T14:09:03.608126Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-367-f5943a3eab95>, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-367-f5943a3eab95>\"\u001b[0;36m, line \u001b[0;32m44\u001b[0m\n\u001b[0;31m    Sum =\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "D = 2 # dimention\n",
    "c = 0 # constant\n",
    "N = 2 # number of data\n",
    "sigma2y = 1 \n",
    "\n",
    "\n",
    "std = 1\n",
    "\n",
    "## a random draw from N~(theta2+theta1^2,1)\n",
    "@tf.function\n",
    "def f(theta1,theta2):\n",
    "    k = tf.add(theta2,tf.pow(theta1,2.))\n",
    "#     x = tf.random.normal([],mean = k,stddev = std)\n",
    "#     return tf.convert_to_tensor(x,dtype=tf.float32)\n",
    "    return k\n",
    "\n",
    "prior = tf.convert_to_tensor([0.,0.])\n",
    "cov = tf.convert_to_tensor([[1.,0.],[0.,1.]])\n",
    "\n",
    "# mvn = tfd.MultivariateNormalFullCovariance(loc=prior, covariance_matrix=cov)\n",
    "\n",
    "@tf.function\n",
    "def matrixcompute(matrix1,matrix2,Cov):\n",
    "\n",
    "    matrix = tf.subtract(matrix1, matrix2)\n",
    "    matrix = tf.reshape(matrix,[matrix.shape[0],1])\n",
    "    matrix_T = tf.transpose(matrix)\n",
    "    Cov_inv = tf.linalg.inv(Cov)\n",
    "    result = tf.multiply(tf.constant(1/2),tf.matmul(tf.matmul(matrix_T,Cov_inv),matrix))\n",
    "    return result\n",
    "\n",
    "\n",
    "y = np.random.normal(loc =c, scale = sigma2y, size = N) ## obervation data\n",
    "\n",
    "sq_sum_y = np.sum(y**2)\n",
    "mean_y = np.mean(y)\n",
    "\n",
    "# y = tf.convert_to_tensor(y,dtype = tf.float32)\n",
    "# y =  tf.data.Dataset.from_tensor_slices(y)\n",
    "\n",
    "@tf.function\n",
    "def log_post(theta1, theta2):\n",
    "    ## Calculate the negative log posterior\n",
    "    Sum = \n",
    "    ## Negative log likelihood\n",
    "    log_likelihood = (1/2)* Sum/(std**2)\n",
    "    mu=tf.convert_to_tensor([theta1,theta2])\n",
    "    mu = tf.reshape(mu,[2,])\n",
    "    ## Negative log prior\n",
    "    log_prior = matrixcompute(mu, prior, cov)\n",
    "    log_posterior = log_likelihood+log_prior\n",
    "    \n",
    "    return(log_posterior)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> find the MAP point by Gradient decent<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T15:02:43.722121Z",
     "start_time": "2019-11-12T15:02:43.304486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-1312.5513     -56.127563], shape=(2,), dtype=float32)\n",
      "tf.Tensor([ 2.7134121e+09 -1.0336971e+06], shape=(2,), dtype=float32)\n",
      "tf.Tensor([-2.3973339e+28 -4.4175634e+18], shape=(2,), dtype=float32)\n",
      "tf.Tensor([ inf -inf], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n",
      "tf.Tensor([nan nan], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "D = 2 # dimention\n",
    "c = 0 # constant\n",
    "N = 100 # number of data\n",
    "sigma2y = 1 \n",
    "\n",
    "\n",
    "std = 1\n",
    "\n",
    "## a random draw from N~(theta2+theta1^2,1)\n",
    "@tf.function\n",
    "def f(theta1,theta2):\n",
    "    k = tf.add(theta2,tf.pow(theta1,2.))\n",
    "#     x = tf.random.normal([],mean = k,stddev = std)\n",
    "#     return tf.convert_to_tensor(x,dtype=tf.float32)\n",
    "    return k\n",
    "\n",
    "lr = 0.1  \n",
    "y = np.random.normal(loc =c, scale = sigma2y, size = N) ## obervation data\n",
    "x = tf.constant([10.,10.])\n",
    "for i in range(100):\n",
    "    with tf.GradientTape() as t:  \n",
    "        t.watch(x)\n",
    "     \n",
    "        Sum =  (y[0]-f(x[0],x[1]))**2+ (y[1]-f(x[0],x[1]))**2+(y[2]-f(x[0],x[1]))**2\n",
    "                 \n",
    "        dx = t.gradient(Sum,x)\n",
    "        x = x-lr*dx\n",
    "        print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T10:47:02.568202Z",
     "start_time": "2019-11-12T10:47:02.563181Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss(theta1,theta2):\n",
    "    return (log_post(theta1,theta2))\n",
    "\n",
    "def loss_minimize():\n",
    "    return (log_post(theta1,theta2))\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "step = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T10:47:04.709527Z",
     "start_time": "2019-11-12T10:47:03.356113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97.694595]\n",
      "[3.7889543] [-5.1314926]\n",
      "[14095.973]\n",
      "[-11.188242] [-7.107921]\n",
      "[7.318266e+10]\n",
      "[520.1472] [-30.853182]\n",
      "[1.0035646e+31]\n",
      "[-56284180.] [-54135.44]\n",
      "[inf]\n",
      "[7.132126e+22] [-6.3358176e+14]\n",
      "[nan]\n",
      "[-inf] [-inf]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n",
      "[nan]\n",
      "[nan] [nan]\n"
     ]
    }
   ],
   "source": [
    "dtype = np.float32\n",
    "\n",
    "\n",
    "\n",
    "true_mean = [0, 0]\n",
    "true_cov = [[1, 0],\n",
    "                 [0, 1]]\n",
    "num_results = 1000\n",
    "num_chains = 1\n",
    "\n",
    "\n",
    "target = tfd.MultivariateNormalFullCovariance(loc=true_mean, covariance_matrix=true_cov)\n",
    "\n",
    "# Assume that the state is passed as a list of 1-d tensors `x` and `y`.\n",
    "# Then the target log-density is defined as follows:\n",
    "def target_log_prob(x, y):\n",
    "  # Stack the input tensors together\n",
    "  z = tf.stack([x, x**2+y], axis=-1)\n",
    "  return target.log_prob(tf.squeeze(z))\n",
    "\n",
    "# Initial state of the chain\n",
    "init_state = [-3.,\n",
    "              -2.]\n",
    "\n",
    "# Run Random Walk Metropolis with normal proposal for `num_results`\n",
    "# iterations for `num_chains` independent chains:\n",
    "samples, kernel_results = tfp.mcmc.sample_chain(\n",
    "    num_results=num_results,\n",
    "    current_state=init_state,\n",
    "    kernel=tfp.mcmc.HamiltonianMonteCarlo(\n",
    "        target_log_prob_fn=target_log_prob,\n",
    "        step_size = 0.1,\n",
    "        num_leapfrog_steps = 5),\n",
    "    num_burnin_steps=500,\n",
    "    num_steps_between_results=1,  # Thinning.\n",
    "    parallel_iterations=1)\n",
    "samples = tf.stack(samples, axis=-1)\n",
    "\n",
    "accepted = kernel_results.is_accepted\n",
    "\n",
    "samples = samples.numpy()\n",
    "accepted = accepted.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
